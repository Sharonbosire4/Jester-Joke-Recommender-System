{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content based Jokes recommendation system using topic modelling apporach !!\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "    Topic modelling is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. We will try to find topic of the joke which can be used as the joke tag !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jokes',), ('ratings',), ('normalized_ratings',)]\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports !\n",
    "import nltk\n",
    "import sqlite3 as db\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# loading data from sql database\n",
    "database = 'data/jester_jokes.db'\n",
    "conn = db.connect(database)\n",
    "\n",
    "query = 'SELECT * FROM jokes'\n",
    "jokes = pd.read_sql(query, conn)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Looking at jokes raw data !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke_id</th>\n",
       "      <th>joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nA man visits the doctor. The doctor says \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>|  \\n\\n  \\nTwo cannibals are eating a clown, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>\\n  \\nQ: Whats the difference between greeti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>|  \\n\\n  \\nQ. What do a hurricane, a tornado, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>|  \\n\\n  \\nA guy stood over his tee shot for w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   joke_id                                               joke\n",
       "0        1    \\nA man visits the doctor. The doctor says \"...\n",
       "1       10  |  \\n\\n  \\nTwo cannibals are eating a clown, o...\n",
       "2      100    \\n  \\nQ: Whats the difference between greeti...\n",
       "3       11  |  \\n\\n  \\nQ. What do a hurricane, a tornado, ...\n",
       "4       12  |  \\n\\n  \\nA guy stood over his tee shot for w..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since raw data is very dirty, we will first clean the data. The basic cleaning will involve following steps !!\n",
    "\n",
    "##### Text cleaning steps:\n",
    "\n",
    "    a. Convert to lowercase, \n",
    "    b. Keep only alphanumeric characters and space, \n",
    "    c. Replace anything else with whitespace, \n",
    "    d. Strip extra white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke_id</th>\n",
       "      <th>joke</th>\n",
       "      <th>cleanedText1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nA man visits the doctor. The doctor says \"...</td>\n",
       "      <td>a man visits the doctor the doctor says i have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>|  \\n\\n  \\nTwo cannibals are eating a clown, o...</td>\n",
       "      <td>two cannibals are eating a clown one turns to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>\\n  \\nQ: Whats the difference between greeti...</td>\n",
       "      <td>q whats the difference between greeting a quee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>|  \\n\\n  \\nQ. What do a hurricane, a tornado, ...</td>\n",
       "      <td>q what do a hurricane a tornado and a redneck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>|  \\n\\n  \\nA guy stood over his tee shot for w...</td>\n",
       "      <td>a guy stood over his tee shot for what seemed ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   joke_id                                               joke  \\\n",
       "0        1    \\nA man visits the doctor. The doctor says \"...   \n",
       "1       10  |  \\n\\n  \\nTwo cannibals are eating a clown, o...   \n",
       "2      100    \\n  \\nQ: Whats the difference between greeti...   \n",
       "3       11  |  \\n\\n  \\nQ. What do a hurricane, a tornado, ...   \n",
       "4       12  |  \\n\\n  \\nA guy stood over his tee shot for w...   \n",
       "\n",
       "                                        cleanedText1  \n",
       "0  a man visits the doctor the doctor says i have...  \n",
       "1  two cannibals are eating a clown one turns to ...  \n",
       "2  q whats the difference between greeting a quee...  \n",
       "3  q what do a hurricane a tornado and a redneck ...  \n",
       "4  a guy stood over his tee shot for what seemed ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def cleanText(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w+\\s]', ' ', text)\n",
    "    text = re.sub(r\"\\s+\", ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# save the cleaned data into a new column named cleanedText1 \n",
    "jokes['cleanedText1'] = jokes['joke'].apply(lambda x: cleanText(x))\n",
    "jokes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords\n",
    "    We will filter out most common words, which are neutral and doesn't imply any category!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One way to use stop word is by using nltk stopwords, but we will be using stopwords based in the jokes text\n",
    "    '''\n",
    "    from nltk.corpus import stopwords  \n",
    "    stopwords = list(set(stopwords.words('english')))\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke_id</th>\n",
       "      <th>joke</th>\n",
       "      <th>cleanedText1</th>\n",
       "      <th>cleanedText2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nA man visits the doctor. The doctor says \"...</td>\n",
       "      <td>a man visits the doctor the doctor says i have...</td>\n",
       "      <td>man visits doctor doctor says bad news cancer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>|  \\n\\n  \\nTwo cannibals are eating a clown, o...</td>\n",
       "      <td>two cannibals are eating a clown one turns to ...</td>\n",
       "      <td>two cannibals eating clown one turns says tast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>\\n  \\nQ: Whats the difference between greeti...</td>\n",
       "      <td>q whats the difference between greeting a quee...</td>\n",
       "      <td>q whats difference greeting queen greeting pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>|  \\n\\n  \\nQ. What do a hurricane, a tornado, ...</td>\n",
       "      <td>q what do a hurricane a tornado and a redneck ...</td>\n",
       "      <td>q hurricane tornado redneck divorce common som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>|  \\n\\n  \\nA guy stood over his tee shot for w...</td>\n",
       "      <td>a guy stood over his tee shot for what seemed ...</td>\n",
       "      <td>guy stood tee shot seemed eternity looking loo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   joke_id                                               joke  \\\n",
       "0        1    \\nA man visits the doctor. The doctor says \"...   \n",
       "1       10  |  \\n\\n  \\nTwo cannibals are eating a clown, o...   \n",
       "2      100    \\n  \\nQ: Whats the difference between greeti...   \n",
       "3       11  |  \\n\\n  \\nQ. What do a hurricane, a tornado, ...   \n",
       "4       12  |  \\n\\n  \\nA guy stood over his tee shot for w...   \n",
       "\n",
       "                                        cleanedText1  \\\n",
       "0  a man visits the doctor the doctor says i have...   \n",
       "1  two cannibals are eating a clown one turns to ...   \n",
       "2  q whats the difference between greeting a quee...   \n",
       "3  q what do a hurricane a tornado and a redneck ...   \n",
       "4  a guy stood over his tee shot for what seemed ...   \n",
       "\n",
       "                                        cleanedText2  \n",
       "0  man visits doctor doctor says bad news cancer ...  \n",
       "1  two cannibals eating clown one turns says tast...  \n",
       "2  q whats difference greeting queen greeting pre...  \n",
       "3  q hurricane tornado redneck divorce common som...  \n",
       "4  guy stood tee shot seemed eternity looking loo...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = [\"---\",\"---|---\",\"i\", \"me\", \"my\", \"myself\", \"we\",\n",
    "             \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\",\n",
    "             \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\",\n",
    "             \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n",
    "             \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\",\n",
    "             \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\",\n",
    "             \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\",\n",
    "             \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\",\n",
    "             \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\",\n",
    "             \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\",\n",
    "             \"against\", \"between\", \"into\", \"through\", \"during\", \"before\",\n",
    "             \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\",\n",
    "             \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\",\n",
    "             \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\",\n",
    "             \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\",\n",
    "             \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n",
    "             \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "def removeStopwords(text):\n",
    "    words = text.split(' ')\n",
    "    new_words = []\n",
    "    for w in words:\n",
    "        if w in stopwords:\n",
    "            pass\n",
    "        else:\n",
    "            new_words.append(w)\n",
    "    return ' '.join(new_words)\n",
    "    \n",
    "# saving into new column as clearText2\n",
    "jokes['cleanedText2'] = jokes['cleanedText1'].apply(lambda x: removeStopwords(x))\n",
    "jokes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmetization\n",
    "We will group together the inflected forms of a word so they can be analysed as a single item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n",
      "greeting : greet\n",
      "greeting : greeting\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
    "  \n",
    "# a denotes adjective in \"pos\" \n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n",
    "\n",
    "# v denotes verb in \"pos\" and n denotes noun \n",
    "print(\"greeting :\", lemmatizer.lemmatize(\"greeting\", pos =\"v\"))\n",
    "print(\"greeting :\", lemmatizer.lemmatize(\"greeting\", pos =\"n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    In the above two examples, first greeting is verb so after Lemmetization it become greet, another greeting is noun so even after Lemmetization it remains same\n",
    "    \n",
    "##### Performing Lemmetization over entire jokes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke_id</th>\n",
       "      <th>joke</th>\n",
       "      <th>cleanedText1</th>\n",
       "      <th>cleanedText2</th>\n",
       "      <th>cleanedText3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nA man visits the doctor. The doctor says \"...</td>\n",
       "      <td>a man visits the doctor the doctor says i have...</td>\n",
       "      <td>man visits doctor doctor says bad news cancer ...</td>\n",
       "      <td>man visit doctor doctor say bad news cancer al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>|  \\n\\n  \\nTwo cannibals are eating a clown, o...</td>\n",
       "      <td>two cannibals are eating a clown one turns to ...</td>\n",
       "      <td>two cannibals eating clown one turns says tast...</td>\n",
       "      <td>two cannibal eating clown one turn say taste f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   joke_id                                               joke  \\\n",
       "0        1    \\nA man visits the doctor. The doctor says \"...   \n",
       "1       10  |  \\n\\n  \\nTwo cannibals are eating a clown, o...   \n",
       "\n",
       "                                        cleanedText1  \\\n",
       "0  a man visits the doctor the doctor says i have...   \n",
       "1  two cannibals are eating a clown one turns to ...   \n",
       "\n",
       "                                        cleanedText2  \\\n",
       "0  man visits doctor doctor says bad news cancer ...   \n",
       "1  two cannibals eating clown one turns says tast...   \n",
       "\n",
       "                                        cleanedText3  \n",
       "0  man visit doctor doctor say bad news cancer al...  \n",
       "1  two cannibal eating clown one turn say taste f...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize \n",
    "   \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "   \n",
    "def performLemmatization(text):\n",
    "    words = word_tokenize(text)\n",
    "    new_words=[]\n",
    "    \n",
    "    for w in words:\n",
    "        new_words.append(lemmatizer.lemmatize(w))\n",
    "        \n",
    "    return ' '.join(new_words)\n",
    "\n",
    "# saving into cleanedText3\n",
    "jokes['cleanedText3'] = jokes['cleanedText2'].apply(lambda x: performLemmatization(x))\n",
    "jokes.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Of Speech tagging or PoS Tagging !\n",
    "    We will separate each word any try to find out their parts of speech!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke_id</th>\n",
       "      <th>joke</th>\n",
       "      <th>cleanedText1</th>\n",
       "      <th>cleanedText2</th>\n",
       "      <th>cleanedText3</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nA man visits the doctor. The doctor says \"...</td>\n",
       "      <td>a man visits the doctor the doctor says i have...</td>\n",
       "      <td>man visits doctor doctor says bad news cancer ...</td>\n",
       "      <td>man visit doctor doctor say bad news cancer al...</td>\n",
       "      <td>[(man, NOUN), (visits, NOUN), (doctor, VERB), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>|  \\n\\n  \\nTwo cannibals are eating a clown, o...</td>\n",
       "      <td>two cannibals are eating a clown one turns to ...</td>\n",
       "      <td>two cannibals eating clown one turns says tast...</td>\n",
       "      <td>two cannibal eating clown one turn say taste f...</td>\n",
       "      <td>[(two, NUM), (cannibals, NOUN), (eating, VERB)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   joke_id                                               joke  \\\n",
       "0        1    \\nA man visits the doctor. The doctor says \"...   \n",
       "1       10  |  \\n\\n  \\nTwo cannibals are eating a clown, o...   \n",
       "\n",
       "                                        cleanedText1  \\\n",
       "0  a man visits the doctor the doctor says i have...   \n",
       "1  two cannibals are eating a clown one turns to ...   \n",
       "\n",
       "                                        cleanedText2  \\\n",
       "0  man visits doctor doctor says bad news cancer ...   \n",
       "1  two cannibals eating clown one turns says tast...   \n",
       "\n",
       "                                        cleanedText3  \\\n",
       "0  man visit doctor doctor say bad news cancer al...   \n",
       "1  two cannibal eating clown one turn say taste f...   \n",
       "\n",
       "                                            pos_tags  \n",
       "0  [(man, NOUN), (visits, NOUN), (doctor, VERB), ...  \n",
       "1  [(two, NUM), (cannibals, NOUN), (eating, VERB)...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def posTagging(text):\n",
    "    text = nltk.word_tokenize(text)\n",
    "    return pos_tag(text, tagset='universal')\n",
    "\n",
    "# saving in new column as 'pos_tags'\n",
    "jokes['pos_tags'] = jokes['cleanedText2'].apply(lambda x: posTagging(x))\n",
    "jokes.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pos_tags are in list from, so we will separate it in all forms of part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke_id</th>\n",
       "      <th>joke</th>\n",
       "      <th>cleanedText1</th>\n",
       "      <th>cleanedText2</th>\n",
       "      <th>cleanedText3</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRT</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PUNC</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nA man visits the doctor. The doctor says \"...</td>\n",
       "      <td>a man visits the doctor the doctor says i have...</td>\n",
       "      <td>man visits doctor doctor says bad news cancer ...</td>\n",
       "      <td>man visit doctor doctor say bad news cancer al...</td>\n",
       "      <td>[(man, NOUN), (visits, NOUN), (doctor, VERB), ...</td>\n",
       "      <td>[bad, thank]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[well]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[man, visits, doctor, news, cancer, alzheimer,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[doctor, says, replies]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>|  \\n\\n  \\nTwo cannibals are eating a clown, o...</td>\n",
       "      <td>two cannibals are eating a clown one turns to ...</td>\n",
       "      <td>two cannibals eating clown one turns says tast...</td>\n",
       "      <td>two cannibal eating clown one turn say taste f...</td>\n",
       "      <td>[(two, NUM), (cannibals, NOUN), (eating, VERB)...</td>\n",
       "      <td>[clown]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[cannibals, taste, funny]</td>\n",
       "      <td>[two, one]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[eating, turns, says]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   joke_id                                               joke  \\\n",
       "0        1    \\nA man visits the doctor. The doctor says \"...   \n",
       "1       10  |  \\n\\n  \\nTwo cannibals are eating a clown, o...   \n",
       "\n",
       "                                        cleanedText1  \\\n",
       "0  a man visits the doctor the doctor says i have...   \n",
       "1  two cannibals are eating a clown one turns to ...   \n",
       "\n",
       "                                        cleanedText2  \\\n",
       "0  man visits doctor doctor says bad news cancer ...   \n",
       "1  two cannibals eating clown one turns says tast...   \n",
       "\n",
       "                                        cleanedText3  \\\n",
       "0  man visit doctor doctor say bad news cancer al...   \n",
       "1  two cannibal eating clown one turn say taste f...   \n",
       "\n",
       "                                            pos_tags           ADJ ADP  \\\n",
       "0  [(man, NOUN), (visits, NOUN), (doctor, VERB), ...  [bad, thank]  []   \n",
       "1  [(two, NUM), (cannibals, NOUN), (eating, VERB)...       [clown]  []   \n",
       "\n",
       "      ADV CONJ DET                                               NOUN  \\\n",
       "0  [well]   []  []  [man, visits, doctor, news, cancer, alzheimer,...   \n",
       "1      []   []  []                          [cannibals, taste, funny]   \n",
       "\n",
       "          NUM PRT PRON                     VERB PUNC OTHERS  \n",
       "0          []  []   []  [doctor, says, replies]   []     []  \n",
       "1  [two, one]  []   []    [eating, turns, says]   []     []  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "jokes['ADJ'] = pd.Series(dtype=str)\n",
    "jokes['ADP'] = pd.Series(dtype=str)\n",
    "jokes['ADV'] = pd.Series(dtype=str)\n",
    "jokes['CONJ'] = pd.Series(dtype=str)\n",
    "jokes['DET'] = pd.Series(dtype=str)\n",
    "jokes['NOUN'] = pd.Series(dtype=str)\n",
    "jokes['NUM'] = pd.Series(dtype=str)\n",
    "jokes['PRT'] = pd.Series(dtype=str)\n",
    "jokes['PRON'] = pd.Series(dtype=str)\n",
    "jokes['PRT'] = pd.Series(dtype=str)\n",
    "jokes['PRON'] = pd.Series(dtype=str)\n",
    "jokes['VERB'] = pd.Series(dtype=str)\n",
    "jokes['PUNC'] = pd.Series(dtype=str)\n",
    "jokes['OTHERS'] = pd.Series(dtype=str)\n",
    "\n",
    "\n",
    "for i in range(len(jokes)):\n",
    "\n",
    "    pos_tags = jokes['pos_tags'][i]\n",
    "\n",
    "    ADJ = []\n",
    "    ADP = []\n",
    "    ADV = []\n",
    "    CONJ = []\n",
    "    DET = []\n",
    "    NOUN = []\n",
    "    NUM = []\n",
    "    PRT = []\n",
    "    PRON = []\n",
    "    VERB = []\n",
    "    PUNC = []\n",
    "    OTHERS = []\n",
    "\n",
    "    for tag in pos_tags:\n",
    "        if tag[1] == 'ADJ':\n",
    "            ADJ.append(tag[0])\n",
    "        if tag[1] == 'ADP':\n",
    "            ADP.append(tag[0])\n",
    "        if tag[1] == 'ADV':\n",
    "            ADV.append(tag[0])\n",
    "        if tag[1] == 'CONJ':\n",
    "            CONJ.append(tag[0])\n",
    "        if tag[1] == 'DET':\n",
    "            DET.append(tag[0])\n",
    "        if tag[1] == 'NOUN':\n",
    "            NOUN.append(tag[0])\n",
    "        if tag[1] == 'NUM':\n",
    "            NUM.append(tag[0])\n",
    "        if tag[1] == 'PRT':\n",
    "            PRT.append(tag[0])\n",
    "        if tag[1] == 'PRON':\n",
    "            PRON.append(tag[0])\n",
    "        if tag[1] == 'VERB':\n",
    "            VERB.append(tag[0])\n",
    "        if tag[1] == '.':\n",
    "            PUNC.append(tag[0])\n",
    "        if tag[1] == 'X':\n",
    "            OTHERS.append(tag[0])\n",
    "\n",
    "    jokes['ADJ'][i] = ADJ\n",
    "    jokes['ADP'][i] = ADP\n",
    "    jokes['ADV'][i] = ADV\n",
    "    jokes['CONJ'][i] = CONJ\n",
    "    jokes['DET'][i] = DET\n",
    "    jokes['NOUN'][i] = NOUN\n",
    "    jokes['NUM'][i] = NUM\n",
    "    jokes['PRT'][i] = PRT\n",
    "    jokes['PRON'][i] = PRON\n",
    "    jokes['PRT'][i] = PRT\n",
    "    jokes['PRON'][i] = PRON\n",
    "    jokes['VERB'][i] = VERB\n",
    "    jokes['PUNC'][i] = PUNC\n",
    "    jokes['OTHERS'][i] = OTHERS\n",
    "\n",
    "# saving the data into csv format for later use !\n",
    "jokes.to_csv('data/jokes_postags.csv', index=False)\n",
    "jokes.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJ: 494\n",
      "ADP: 39\n",
      "ADV: 168\n",
      "CONJ: 0\n",
      "DET: 18\n",
      "NOUN: 1463\n",
      "NUM: 140\n",
      "PRT: 4\n",
      "PRON: 16\n",
      "VERB: 766\n",
      "PUNC: 1\n",
      "OTHERS: 5\n"
     ]
    }
   ],
   "source": [
    "jokes_postags = pd.read_csv('data/jokes_postags.csv')\n",
    "\n",
    "ADJ = []\n",
    "ADP = []\n",
    "ADV = []\n",
    "CONJ = []\n",
    "DET = []\n",
    "NOUN = []\n",
    "NUM = []\n",
    "PRT = []\n",
    "PRON = []\n",
    "VERB = []\n",
    "PUNC = []\n",
    "OTHERS = []\n",
    "\n",
    "for i in range(len(jokes_postags)):\n",
    "    ADJ.extend(jokes['ADJ'][i])\n",
    "    ADP.extend(jokes['ADP'][i])\n",
    "    ADV.extend(jokes['ADV'][i])\n",
    "    CONJ.extend(jokes['CONJ'][i])\n",
    "    DET.extend(jokes['DET'][i])\n",
    "    NOUN.extend(jokes['NOUN'][i])\n",
    "    NUM.extend(jokes['NUM'][i])\n",
    "    PRT.extend(jokes['PRT'][i])\n",
    "    PRON.extend(jokes['PRON'][i])\n",
    "    PRT.extend(jokes['PRT'][i]) \n",
    "    PRON.extend(jokes['PRON'][i])\n",
    "    VERB.extend(jokes['VERB'][i]) \n",
    "    PUNC.extend(jokes['PUNC'][i]) \n",
    "    OTHERS.extend(jokes['OTHERS'][i])\n",
    "\n",
    "print(\"ADJ: \"+str(len(ADJ)))\n",
    "print(\"ADP: \"+str(len(ADP)))\n",
    "print(\"ADV: \"+str(len(ADV)))\n",
    "print(\"CONJ: \"+str(len(CONJ)))\n",
    "print(\"DET: \"+str(len(DET)))\n",
    "print(\"NOUN: \"+str(len(NOUN)))\n",
    "print(\"NUM: \"+str(len(NUM)))\n",
    "print(\"PRT: \"+str(len(PRT)))\n",
    "print(\"PRON: \"+str(len(PRON)))\n",
    "print(\"VERB: \"+str(len(VERB)))\n",
    "print(\"PUNC: \"+str(len(PUNC)))\n",
    "print(\"OTHERS: \"+str(len(OTHERS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by POS tag, length of word should be greater than 1 and they belong to noun and verb only !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes1 = pd.read_csv('data/jokes_postags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke_id</th>\n",
       "      <th>joke</th>\n",
       "      <th>cleanedText1</th>\n",
       "      <th>cleanedText2</th>\n",
       "      <th>cleanedText3</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRT</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PUNC</th>\n",
       "      <th>OTHERS</th>\n",
       "      <th>cleanedText4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nA man visits the doctor. The doctor says \"...</td>\n",
       "      <td>a man visits the doctor the doctor says i have...</td>\n",
       "      <td>man visits doctor doctor says bad news cancer ...</td>\n",
       "      <td>man visit doctor doctor say bad news cancer al...</td>\n",
       "      <td>[('man', 'NOUN'), ('visits', 'NOUN'), ('doctor...</td>\n",
       "      <td>['bad', 'thank']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['well']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['man', 'visits', 'doctor', 'news', 'cancer', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['doctor', 'says', 'replies']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>man visits doctor doctor says news cancer alzh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>|  \\n\\n  \\nTwo cannibals are eating a clown, o...</td>\n",
       "      <td>two cannibals are eating a clown one turns to ...</td>\n",
       "      <td>two cannibals eating clown one turns says tast...</td>\n",
       "      <td>two cannibal eating clown one turn say taste f...</td>\n",
       "      <td>[('two', 'NUM'), ('cannibals', 'NOUN'), ('eati...</td>\n",
       "      <td>['clown']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['cannibals', 'taste', 'funny']</td>\n",
       "      <td>['two', 'one']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['eating', 'turns', 'says']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cannibals eating turns says taste funny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   joke_id                                               joke  \\\n",
       "0        1    \\nA man visits the doctor. The doctor says \"...   \n",
       "1       10  |  \\n\\n  \\nTwo cannibals are eating a clown, o...   \n",
       "\n",
       "                                        cleanedText1  \\\n",
       "0  a man visits the doctor the doctor says i have...   \n",
       "1  two cannibals are eating a clown one turns to ...   \n",
       "\n",
       "                                        cleanedText2  \\\n",
       "0  man visits doctor doctor says bad news cancer ...   \n",
       "1  two cannibals eating clown one turns says tast...   \n",
       "\n",
       "                                        cleanedText3  \\\n",
       "0  man visit doctor doctor say bad news cancer al...   \n",
       "1  two cannibal eating clown one turn say taste f...   \n",
       "\n",
       "                                            pos_tags               ADJ ADP  \\\n",
       "0  [('man', 'NOUN'), ('visits', 'NOUN'), ('doctor...  ['bad', 'thank']  []   \n",
       "1  [('two', 'NUM'), ('cannibals', 'NOUN'), ('eati...         ['clown']  []   \n",
       "\n",
       "        ADV CONJ DET                                               NOUN  \\\n",
       "0  ['well']   []  []  ['man', 'visits', 'doctor', 'news', 'cancer', ...   \n",
       "1        []   []  []                    ['cannibals', 'taste', 'funny']   \n",
       "\n",
       "              NUM PRT PRON                           VERB PUNC OTHERS  \\\n",
       "0              []  []   []  ['doctor', 'says', 'replies']   []     []   \n",
       "1  ['two', 'one']  []   []    ['eating', 'turns', 'says']   []     []   \n",
       "\n",
       "                                        cleanedText4  \n",
       "0  man visits doctor doctor says news cancer alzh...  \n",
       "1            cannibals eating turns says taste funny  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def filterByPOS(tags):\n",
    "    txt = []\n",
    "    tags = tags[1:len(txt)-1]\n",
    "    tags = ast.literal_eval(tags)\n",
    "    for t in tags:\n",
    "        if t[1] in ['NOUN', 'VERB'] and len(t[0])>1:\n",
    "            txt.append(t[0])\n",
    "            \n",
    "    return ' '.join(txt)\n",
    "\n",
    "jokes1['cleanedText4'] = jokes1['pos_tags'].apply(lambda x: filterByPOS(x))\n",
    "jokes1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the data into csv file\n",
    "jokes1.to_csv(\"data/jokes_postags_filtered.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling with LDA\n",
    "\n",
    "    latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = jokes1['cleanedText4'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "# dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
    "\n",
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1102 unique tokens: ['alzheimer', 'cancer', 'disease', 'doctor', 'god']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([(0.026647301, 'said'),\n",
      "   (0.023817781, 'would'),\n",
      "   (0.017108733, 'house'),\n",
      "   (0.017108386, 'get'),\n",
      "   (0.013756157, 'engineer'),\n",
      "   (0.013752768, 'time'),\n",
      "   (0.013750262, 'guess'),\n",
      "   (0.010399552, 'died'),\n",
      "   (0.010399382, 'asks'),\n",
      "   (0.010398618, 'bed'),\n",
      "   (0.010395802, 'used'),\n",
      "   (0.010394557, 'shook'),\n",
      "   (0.010391887, 'head'),\n",
      "   (0.010364236, 'going'),\n",
      "   (0.007187417, 'says'),\n",
      "   (0.007045757, 'seated'),\n",
      "   (0.007045757, 'take'),\n",
      "   (0.007045757, 'll'),\n",
      "   (0.007045757, 'look'),\n",
      "   (0.007045757, 'began')],\n",
      "  -11.903535654848776),\n",
      " ([(0.022964284, 'says'),\n",
      "   (0.013340671, 'make'),\n",
      "   (0.010086814, 'call'),\n",
      "   (0.010086814, 'builder'),\n",
      "   (0.010086813, 'guy'),\n",
      "   (0.010086812, 'languages'),\n",
      "   (0.0100848405, 'girl'),\n",
      "   (0.010082304, 'married'),\n",
      "   (0.010081645, 'dad'),\n",
      "   (0.010081515, 'william'),\n",
      "   (0.010080126, 'news'),\n",
      "   (0.0073465854, 'said'),\n",
      "   (0.0068329484, 'built'),\n",
      "   (0.0068329484, 'road'),\n",
      "   (0.0068329484, 'see'),\n",
      "   (0.0068329484, 'pier'),\n",
      "   (0.0068329484, 'beer'),\n",
      "   (0.0068329484, 'stone'),\n",
      "   (0.0068329484, 'look'),\n",
      "   (0.0068329484, 'laid')],\n",
      "  -13.41495155339934),\n",
      " ([(0.03806009, 'room'),\n",
      "   (0.02062793, 'says'),\n",
      "   (0.01772257, 'man'),\n",
      "   (0.017722568, 'fire'),\n",
      "   (0.014817205, 'go'),\n",
      "   (0.011911844, 'water'),\n",
      "   (0.011911843, 'bill'),\n",
      "   (0.011911843, 'pass'),\n",
      "   (0.009006479, 'wakes'),\n",
      "   (0.009006479, 'gates'),\n",
      "   (0.009006479, 'looks'),\n",
      "   (0.009006479, 'st'),\n",
      "   (0.009006479, 'arrives'),\n",
      "   (0.009006478, 'could'),\n",
      "   (0.009006478, 'sandwiches'),\n",
      "   (0.009006478, 'goes'),\n",
      "   (0.009006478, 'make'),\n",
      "   (0.009006478, 'time'),\n",
      "   (0.009006478, 'throw'),\n",
      "   (0.009006478, 'religion')],\n",
      "  -13.594824986843586),\n",
      " ([(0.021401936, 'school'),\n",
      "   (0.021401936, 'go'),\n",
      "   (0.021401936, 'man'),\n",
      "   (0.01434631, 'woman'),\n",
      "   (0.014346307, 'says'),\n",
      "   (0.011994432, 'wow'),\n",
      "   (0.009642554, 'want'),\n",
      "   (0.009642554, 'sleeping'),\n",
      "   (0.009642552, 'asked'),\n",
      "   (0.009642552, 'walks'),\n",
      "   (0.0072906744, 'car'),\n",
      "   (0.0072906744, 'measures'),\n",
      "   (0.0072906744, 'got'),\n",
      "   (0.0072906744, 'island'),\n",
      "   (0.0072906744, 'looking'),\n",
      "   (0.0072906744, 'bottle'),\n",
      "   (0.0072906744, 'bob'),\n",
      "   (0.007290674, 'replied'),\n",
      "   (0.007290674, 'boy'),\n",
      "   (0.004940494, 'engineer')],\n",
      "  -13.712966397441045),\n",
      " ([(0.054591767, 'blah'),\n",
      "   (0.021999586, 'says'),\n",
      "   (0.011135521, 'get'),\n",
      "   (0.008419504, 'voice'),\n",
      "   (0.008419504, 'screwed'),\n",
      "   (0.008419504, 'pope'),\n",
      "   (0.005703482, 'left'),\n",
      "   (0.005703482, 'decides'),\n",
      "   (0.005703482, 'stone'),\n",
      "   (0.005703482, 'man'),\n",
      "   (0.005703481, 'okay'),\n",
      "   (0.005703481, 'booms'),\n",
      "   (0.005703481, 'natives'),\n",
      "   (0.005703481, 'walks'),\n",
      "   (0.005703481, 'husband'),\n",
      "   (0.005703481, 'standing'),\n",
      "   (0.005703481, 'got'),\n",
      "   (0.005703481, 'chief'),\n",
      "   (0.005703481, 'll'),\n",
      "   (0.005703481, 'joke')],\n",
      "  -14.228933192924782),\n",
      " ([(0.019388651, 'says'),\n",
      "   (0.019388165, 'man'),\n",
      "   (0.016657421, 'course'),\n",
      "   (0.011197208, 'asks'),\n",
      "   (0.011195925, 'say'),\n",
      "   (0.011195925, 'degrees'),\n",
      "   (0.011195925, 'ship'),\n",
      "   (0.011195924, 'graduate'),\n",
      "   (0.011195924, 'work'),\n",
      "   (0.011195924, 'degree'),\n",
      "   (0.011195923, 'person'),\n",
      "   (0.008466271, 'time'),\n",
      "   (0.0084661655, 'replies'),\n",
      "   (0.0084651755, 'know'),\n",
      "   (0.0084651755, 're'),\n",
      "   (0.0084651755, 'americans'),\n",
      "   (0.0084651755, 'canadians'),\n",
      "   (0.0084651755, 'balloonist'),\n",
      "   (0.0084651755, 'balloon'),\n",
      "   (0.008465174, 'engineer')],\n",
      "  -15.159509225839031),\n",
      " ([(0.012318724, 'bill'),\n",
      "   (0.010299237, 'teller'),\n",
      "   (0.010299237, 'woman'),\n",
      "   (0.0102992365, 'president'),\n",
      "   (0.008279752, 'bear'),\n",
      "   (0.008279751, 'man'),\n",
      "   (0.008279751, 'goes'),\n",
      "   (0.008279751, 'pulls'),\n",
      "   (0.008279751, 'replied'),\n",
      "   (0.008279748, 'engineers'),\n",
      "   (0.006260263, 'pants'),\n",
      "   (0.006260263, 'lawyer'),\n",
      "   (0.006260263, 'says'),\n",
      "   (0.006260263, 'husband'),\n",
      "   (0.006260263, 'look'),\n",
      "   (0.006260263, 'car'),\n",
      "   (0.006260263, 'door'),\n",
      "   (0.006260263, 'panda'),\n",
      "   (0.0062602623, 'engineer'),\n",
      "   (0.0062602623, 'walks')],\n",
      "  -15.315017359319834),\n",
      " ([(0.043310963, 'says'),\n",
      "   (0.034734502, 'news'),\n",
      "   (0.026158048, 'doctor'),\n",
      "   (0.02186982, 'man'),\n",
      "   (0.01329336, 'duck'),\n",
      "   (0.01329336, 'broom'),\n",
      "   (0.013293359, 'time'),\n",
      "   (0.009005126, 'confession'),\n",
      "   (0.009005126, 'groom'),\n",
      "   (0.009005126, 'replies'),\n",
      "   (0.009005126, 'telling'),\n",
      "   (0.009005125, 'said'),\n",
      "   (0.009005125, 'stallone'),\n",
      "   (0.009005125, 'swartzeneger'),\n",
      "   (0.009005125, 'want'),\n",
      "   (0.009005125, 'cancer'),\n",
      "   (0.009005123, 'job'),\n",
      "   (0.004716865, 'phone'),\n",
      "   (0.004716865, 'forgot'),\n",
      "   (0.004716865, 'examination')],\n",
      "  -16.200587024815473),\n",
      " ([(0.01747075, 'mile'),\n",
      "   (0.017470747, 'shoes'),\n",
      "   (0.009151237, 'someone'),\n",
      "   (0.009151237, 'walk'),\n",
      "   (0.009151237, 'criticizing'),\n",
      "   (0.009151237, 'criticize'),\n",
      "   (0.009151237, '_you'),\n",
      "   (0.009151237, 'thought'),\n",
      "   (0.00083194807, 'says'),\n",
      "   (0.000831948, 'man'),\n",
      "   (0.000831948, 'difference'),\n",
      "   (0.00083194795, 'take'),\n",
      "   (0.00083194795, 'get'),\n",
      "   (0.0008319479, 'given'),\n",
      "   (0.0008319479, 'darwin'),\n",
      "   (0.0008319479, 'oh'),\n",
      "   (0.0008319479, 'say'),\n",
      "   (0.0008319479, 'change'),\n",
      "   (0.0008319479, 'light'),\n",
      "   (0.0008319479, 'anything')],\n",
      "  -17.235874967590284),\n",
      " ([(0.016336383, 'take'),\n",
      "   (0.016334066, 'engineer'),\n",
      "   (0.013133148, '_she'),\n",
      "   (0.013133146, 'ages'),\n",
      "   (0.013133143, 'slash'),\n",
      "   (0.013133141, 'lightbulb'),\n",
      "   (0.013131392, 'machine'),\n",
      "   (0.009929901, 'station'),\n",
      "   (0.009929898, 'change'),\n",
      "   (0.009929898, 'man'),\n",
      "   (0.009929126, 'problem'),\n",
      "   (0.009928941, 'retired'),\n",
      "   (0.009928773, 'company'),\n",
      "   (0.006726653, 'teacher'),\n",
      "   (0.006726653, 'damn'),\n",
      "   (0.0067266515, 'train'),\n",
      "   (0.0067266515, 'woman'),\n",
      "   (0.0067266515, 'need'),\n",
      "   (0.0067266515, 'satisfy'),\n",
      "   (0.0067266515, 'wants')],\n",
      "  -19.698128579646607)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save trained model for future use\n",
    "model.save(\"model/lda.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get topic assignment for each document\n",
    "### Column 'cluster' containes the probability of belonging to each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = jokes1['cleanedText4'].tolist()\n",
    "\n",
    "cluster = []\n",
    "\n",
    "for d in docs:\n",
    "    bow = dictionary.doc2bow(d.split())\n",
    "    topics = model.get_document_topics(bow, minimum_probability = 0.0)\n",
    "    cluster.append(topics)\n",
    "    \n",
    "jokes1['cluster'] = pd.Series(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke_id</th>\n",
       "      <th>joke</th>\n",
       "      <th>cleanedText1</th>\n",
       "      <th>cleanedText2</th>\n",
       "      <th>cleanedText3</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRT</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PUNC</th>\n",
       "      <th>OTHERS</th>\n",
       "      <th>cleanedText4</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nA man visits the doctor. The doctor says \"...</td>\n",
       "      <td>a man visits the doctor the doctor says i have...</td>\n",
       "      <td>man visits doctor doctor says bad news cancer ...</td>\n",
       "      <td>man visit doctor doctor say bad news cancer al...</td>\n",
       "      <td>[('man', 'NOUN'), ('visits', 'NOUN'), ('doctor...</td>\n",
       "      <td>['bad', 'thank']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['well']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['man', 'visits', 'doctor', 'news', 'cancer', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['doctor', 'says', 'replies']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>man visits doctor doctor says news cancer alzh...</td>\n",
       "      <td>[(0, 0.002828441), (1, 0.0024506196), (2, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>|  \\n\\n  \\nTwo cannibals are eating a clown, o...</td>\n",
       "      <td>two cannibals are eating a clown one turns to ...</td>\n",
       "      <td>two cannibals eating clown one turns says tast...</td>\n",
       "      <td>two cannibal eating clown one turn say taste f...</td>\n",
       "      <td>[('two', 'NUM'), ('cannibals', 'NOUN'), ('eati...</td>\n",
       "      <td>['clown']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['cannibals', 'taste', 'funny']</td>\n",
       "      <td>['two', 'one']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['eating', 'turns', 'says']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cannibals eating turns says taste funny</td>\n",
       "      <td>[(0, 0.005954403), (1, 0.0051590176), (2, 0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   joke_id                                               joke  \\\n",
       "0        1    \\nA man visits the doctor. The doctor says \"...   \n",
       "1       10  |  \\n\\n  \\nTwo cannibals are eating a clown, o...   \n",
       "\n",
       "                                        cleanedText1  \\\n",
       "0  a man visits the doctor the doctor says i have...   \n",
       "1  two cannibals are eating a clown one turns to ...   \n",
       "\n",
       "                                        cleanedText2  \\\n",
       "0  man visits doctor doctor says bad news cancer ...   \n",
       "1  two cannibals eating clown one turns says tast...   \n",
       "\n",
       "                                        cleanedText3  \\\n",
       "0  man visit doctor doctor say bad news cancer al...   \n",
       "1  two cannibal eating clown one turn say taste f...   \n",
       "\n",
       "                                            pos_tags               ADJ ADP  \\\n",
       "0  [('man', 'NOUN'), ('visits', 'NOUN'), ('doctor...  ['bad', 'thank']  []   \n",
       "1  [('two', 'NUM'), ('cannibals', 'NOUN'), ('eati...         ['clown']  []   \n",
       "\n",
       "        ADV CONJ DET                                               NOUN  \\\n",
       "0  ['well']   []  []  ['man', 'visits', 'doctor', 'news', 'cancer', ...   \n",
       "1        []   []  []                    ['cannibals', 'taste', 'funny']   \n",
       "\n",
       "              NUM PRT PRON                           VERB PUNC OTHERS  \\\n",
       "0              []  []   []  ['doctor', 'says', 'replies']   []     []   \n",
       "1  ['two', 'one']  []   []    ['eating', 'turns', 'says']   []     []   \n",
       "\n",
       "                                        cleanedText4  \\\n",
       "0  man visits doctor doctor says news cancer alzh...   \n",
       "1            cannibals eating turns says taste funny   \n",
       "\n",
       "                                             cluster  \n",
       "0  [(0, 0.002828441), (1, 0.0024506196), (2, 0.00...  \n",
       "1  [(0, 0.005954403), (1, 0.0051590176), (2, 0.00...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes1.to_csv(\"data/jokes_topic_probabilities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort topics by probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "sorted_topics = []\n",
    "\n",
    "for i in range(len(jokes)):\n",
    "    sorted_topics.append(sorted(jokes1['cluster'][i],key=itemgetter(1),  reverse=True))\n",
    "    \n",
    "jokes1['sorted_topics'] = pd.Series(sorted_topics)\n",
    "jokes1.head()\n",
    "\n",
    "jokes1.to_csv(\"data/jokes_sorted_topic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the topic with maximum probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_probability_topic = []\n",
    "for i in range(len(jokes)):\n",
    "    maximum_probability_topic.append(jokes1['sorted_topics'][i][0][0])\n",
    "\n",
    "jokes1['main_topic'] = maximum_probability_topic\n",
    "jokes1.to_csv(\"data/jokes_sorted_topic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke_id</th>\n",
       "      <th>joke</th>\n",
       "      <th>cleanedText1</th>\n",
       "      <th>cleanedText2</th>\n",
       "      <th>cleanedText3</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRT</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PUNC</th>\n",
       "      <th>OTHERS</th>\n",
       "      <th>cleanedText4</th>\n",
       "      <th>cluster</th>\n",
       "      <th>sorted_topics</th>\n",
       "      <th>main_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nA man visits the doctor. The doctor says \"...</td>\n",
       "      <td>a man visits the doctor the doctor says i have...</td>\n",
       "      <td>man visits doctor doctor says bad news cancer ...</td>\n",
       "      <td>man visit doctor doctor say bad news cancer al...</td>\n",
       "      <td>[('man', 'NOUN'), ('visits', 'NOUN'), ('doctor...</td>\n",
       "      <td>['bad', 'thank']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['well']</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['doctor', 'says', 'replies']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>man visits doctor doctor says news cancer alzh...</td>\n",
       "      <td>[(0, 0.002828441), (1, 0.0024506196), (2, 0.00...</td>\n",
       "      <td>[(9, 0.9770882), (6, 0.0033219575), (2, 0.0028...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>|  \\n\\n  \\nTwo cannibals are eating a clown, o...</td>\n",
       "      <td>two cannibals are eating a clown one turns to ...</td>\n",
       "      <td>two cannibals eating clown one turns says tast...</td>\n",
       "      <td>two cannibal eating clown one turn say taste f...</td>\n",
       "      <td>[('two', 'NUM'), ('cannibals', 'NOUN'), ('eati...</td>\n",
       "      <td>['clown']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>['two', 'one']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['eating', 'turns', 'says']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cannibals eating turns says taste funny</td>\n",
       "      <td>[(0, 0.005954403), (1, 0.0051590176), (2, 0.00...</td>\n",
       "      <td>[(8, 0.95312816), (6, 0.0069933482), (2, 0.006...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   joke_id                                               joke  \\\n",
       "0        1    \\nA man visits the doctor. The doctor says \"...   \n",
       "1       10  |  \\n\\n  \\nTwo cannibals are eating a clown, o...   \n",
       "\n",
       "                                        cleanedText1  \\\n",
       "0  a man visits the doctor the doctor says i have...   \n",
       "1  two cannibals are eating a clown one turns to ...   \n",
       "\n",
       "                                        cleanedText2  \\\n",
       "0  man visits doctor doctor says bad news cancer ...   \n",
       "1  two cannibals eating clown one turns says tast...   \n",
       "\n",
       "                                        cleanedText3  \\\n",
       "0  man visit doctor doctor say bad news cancer al...   \n",
       "1  two cannibal eating clown one turn say taste f...   \n",
       "\n",
       "                                            pos_tags               ADJ ADP  \\\n",
       "0  [('man', 'NOUN'), ('visits', 'NOUN'), ('doctor...  ['bad', 'thank']  []   \n",
       "1  [('two', 'NUM'), ('cannibals', 'NOUN'), ('eati...         ['clown']  []   \n",
       "\n",
       "        ADV CONJ  ...             NUM PRT PRON                           VERB  \\\n",
       "0  ['well']   []  ...              []  []   []  ['doctor', 'says', 'replies']   \n",
       "1        []   []  ...  ['two', 'one']  []   []    ['eating', 'turns', 'says']   \n",
       "\n",
       "  PUNC OTHERS                                       cleanedText4  \\\n",
       "0   []     []  man visits doctor doctor says news cancer alzh...   \n",
       "1   []     []            cannibals eating turns says taste funny   \n",
       "\n",
       "                                             cluster  \\\n",
       "0  [(0, 0.002828441), (1, 0.0024506196), (2, 0.00...   \n",
       "1  [(0, 0.005954403), (1, 0.0051590176), (2, 0.00...   \n",
       "\n",
       "                                       sorted_topics main_topic  \n",
       "0  [(9, 0.9770882), (6, 0.0033219575), (2, 0.0028...          9  \n",
       "1  [(8, 0.95312816), (6, 0.0069933482), (2, 0.006...          8  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count plot of number of jokes per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "jokes_topic = pd.read_csv(\"data/jokes_sorted_topic.csv\")\n",
    "jokes_topic.head()\n",
    "\n",
    "sns.countplot(x = 'main_topic',\n",
    "            data = jokes_topic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize User Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM ratings'\n",
    "ratings = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>number_of_jokes_rated</th>\n",
       "      <th>joke_1</th>\n",
       "      <th>joke_2</th>\n",
       "      <th>joke_3</th>\n",
       "      <th>joke_4</th>\n",
       "      <th>joke_5</th>\n",
       "      <th>joke_6</th>\n",
       "      <th>joke_7</th>\n",
       "      <th>joke_8</th>\n",
       "      <th>...</th>\n",
       "      <th>joke_91</th>\n",
       "      <th>joke_92</th>\n",
       "      <th>joke_93</th>\n",
       "      <th>joke_94</th>\n",
       "      <th>joke_95</th>\n",
       "      <th>joke_96</th>\n",
       "      <th>joke_97</th>\n",
       "      <th>joke_98</th>\n",
       "      <th>joke_99</th>\n",
       "      <th>joke_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>-7.82</td>\n",
       "      <td>8.79</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>-8.16</td>\n",
       "      <td>-7.52</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>-9.85</td>\n",
       "      <td>4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>2.82</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>-5.63</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>4.08</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>6.36</td>\n",
       "      <td>4.37</td>\n",
       "      <td>-2.38</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-5.34</td>\n",
       "      <td>...</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-4.95</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>7.86</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-4.32</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>9.03</td>\n",
       "      <td>9.27</td>\n",
       "      <td>9.03</td>\n",
       "      <td>9.27</td>\n",
       "      <td>...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>9.08</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>99.00</td>\n",
       "      <td>8.35</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>8.16</td>\n",
       "      <td>-2.82</td>\n",
       "      <td>6.21</td>\n",
       "      <td>...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>91</td>\n",
       "      <td>8.50</td>\n",
       "      <td>4.61</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>-5.39</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.04</td>\n",
       "      <td>4.61</td>\n",
       "      <td>...</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.58</td>\n",
       "      <td>4.27</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.11</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  number_of_jokes_rated  joke_1  joke_2  joke_3  joke_4  joke_5  \\\n",
       "0        1                     74   -7.82    8.79   -9.66   -8.16   -7.52   \n",
       "1        2                    100    4.08   -0.29    6.36    4.37   -2.38   \n",
       "2        3                     49   99.00   99.00   99.00   99.00    9.03   \n",
       "3        4                     48   99.00    8.35   99.00   99.00    1.80   \n",
       "4        5                     91    8.50    4.61   -4.17   -5.39    1.36   \n",
       "\n",
       "   joke_6  joke_7  joke_8  ...  joke_91  joke_92  joke_93  joke_94  joke_95  \\\n",
       "0   -8.50   -9.85    4.17  ...     2.82    99.00    99.00    99.00    99.00   \n",
       "1   -9.66   -0.73   -5.34  ...     2.82    -4.95    -0.29     7.86    -0.19   \n",
       "2    9.27    9.03    9.27  ...    99.00    99.00    99.00     9.08    99.00   \n",
       "3    8.16   -2.82    6.21  ...    99.00    99.00    99.00     0.53    99.00   \n",
       "4    1.60    7.04    4.61  ...     5.19     5.58     4.27     5.19     5.73   \n",
       "\n",
       "   joke_96  joke_97  joke_98  joke_99  joke_100  \n",
       "0    99.00    -5.63    99.00    99.00     99.00  \n",
       "1    -2.14     3.06     0.34    -4.32      1.07  \n",
       "2    99.00    99.00    99.00    99.00     99.00  \n",
       "3    99.00    99.00    99.00    99.00     99.00  \n",
       "4     1.55     3.11     6.55     1.80      1.60  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>number_of_jokes_rated</th>\n",
       "      <th>joke_1</th>\n",
       "      <th>joke_2</th>\n",
       "      <th>joke_3</th>\n",
       "      <th>joke_4</th>\n",
       "      <th>joke_5</th>\n",
       "      <th>joke_6</th>\n",
       "      <th>joke_7</th>\n",
       "      <th>joke_8</th>\n",
       "      <th>...</th>\n",
       "      <th>joke_91</th>\n",
       "      <th>joke_92</th>\n",
       "      <th>joke_93</th>\n",
       "      <th>joke_94</th>\n",
       "      <th>joke_95</th>\n",
       "      <th>joke_96</th>\n",
       "      <th>joke_97</th>\n",
       "      <th>joke_98</th>\n",
       "      <th>joke_99</th>\n",
       "      <th>joke_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-7.82</td>\n",
       "      <td>8.79</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>-8.16</td>\n",
       "      <td>-7.52</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>-9.85</td>\n",
       "      <td>4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>2.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.08</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>6.36</td>\n",
       "      <td>4.37</td>\n",
       "      <td>-2.38</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-5.34</td>\n",
       "      <td>...</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-4.95</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>7.86</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-4.32</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.03</td>\n",
       "      <td>9.27</td>\n",
       "      <td>9.03</td>\n",
       "      <td>9.27</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.80</td>\n",
       "      <td>8.16</td>\n",
       "      <td>-2.82</td>\n",
       "      <td>6.21</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>4.61</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>-5.39</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.04</td>\n",
       "      <td>4.61</td>\n",
       "      <td>...</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.58</td>\n",
       "      <td>4.27</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.11</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  number_of_jokes_rated  joke_1  joke_2  joke_3  joke_4  joke_5  \\\n",
       "0      1.0                   74.0   -7.82    8.79   -9.66   -8.16   -7.52   \n",
       "1      2.0                  100.0    4.08   -0.29    6.36    4.37   -2.38   \n",
       "2      3.0                   49.0     NaN     NaN     NaN     NaN    9.03   \n",
       "3      4.0                   48.0     NaN    8.35     NaN     NaN    1.80   \n",
       "4      5.0                   91.0    8.50    4.61   -4.17   -5.39    1.36   \n",
       "\n",
       "   joke_6  joke_7  joke_8  ...  joke_91  joke_92  joke_93  joke_94  joke_95  \\\n",
       "0   -8.50   -9.85    4.17  ...     2.82      NaN      NaN      NaN      NaN   \n",
       "1   -9.66   -0.73   -5.34  ...     2.82    -4.95    -0.29     7.86    -0.19   \n",
       "2    9.27    9.03    9.27  ...      NaN      NaN      NaN     9.08      NaN   \n",
       "3    8.16   -2.82    6.21  ...      NaN      NaN      NaN     0.53      NaN   \n",
       "4    1.60    7.04    4.61  ...     5.19     5.58     4.27     5.19     5.73   \n",
       "\n",
       "   joke_96  joke_97  joke_98  joke_99  joke_100  \n",
       "0      NaN    -5.63      NaN      NaN       NaN  \n",
       "1    -2.14     3.06     0.34    -4.32      1.07  \n",
       "2      NaN      NaN      NaN      NaN       NaN  \n",
       "3      NaN      NaN      NaN      NaN       NaN  \n",
       "4     1.55     3.11     6.55     1.80      1.60  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace 99 with NaN\n",
    "ratings.replace(99.0, np.nan, inplace=True)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Deviation from mean for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1 = ratings.iloc[:, 2:102]\n",
    "ratings1['mean_rating'] = ratings1.mean(axis=1)\n",
    "ratings1['std_dev'] = ratings1.std(axis=1)\n",
    "\n",
    "for i in range(100):\n",
    "    ratings1[ratings1.columns[i]] = (ratings1[ratings1.columns[i]] - ratings1['mean_rating'])/ratings1['std_dev']\n",
    "    \n",
    "ratings1.head()\n",
    "\n",
    "ratings1.to_csv('data/ratings_standardscalar.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize between -1 and 1 with Robust Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1 = ratings.iloc[:, 2:102]\n",
    "ratings1['quantile1'] = ratings1.quantile(q=0.25, axis=1)\n",
    "ratings1['quantile3'] = ratings1.quantile(q=0.75, axis=1)\n",
    "\n",
    "for i in range(100):\n",
    "    ratings1[ratings1.columns[i]] = (ratings1[ratings1.columns[i]]-ratings1['quantile1'])/(ratings1['quantile3']-ratings1['quantile1'])\n",
    "\n",
    "\n",
    "ratings1['user_id'] = ratings.iloc[:,0]    \n",
    "ratings1['number_of_jokes_rated'] = ratings.iloc[:,1] \n",
    "ratings1.to_csv('data/ratings_robustcalar.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per user stable topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes = pd.read_csv(\"data/jokes_sorted_topic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get joke_id and topic with max probability\n",
    "jokes_topic = jokes[['joke_id','main_topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('data/ratings_robustcalar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get user's rating for each joke_id\n",
    "\n",
    "jokes_rating = pd.DataFrame()\n",
    "jokes_ids = list(range(1,101))\n",
    "user_rating = []\n",
    "\n",
    "#Hard-coded for user_id 0. Need for loop here\n",
    "user_id = 1\n",
    "for i in range(100):\n",
    "    user_rating.append(ratings.iloc[user_id,i])\n",
    "\n",
    "jokes_rating['joke_id']= pd.Series(jokes_ids)\n",
    "jokes_rating['rating'] = pd.Series(user_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = pd.merge(jokes_rating,jokes_topic,on='joke_id')\n",
    "\n",
    "#Sort user ratings in descending order\n",
    "user_ratings.sort_values(by=['rating'],ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print user's rating sorted in descending\n",
    "user_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend joke to user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select an active user and his ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read normalized ratings\n",
    "ratings = pd.read_csv('data/ratings_robustcalar.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select users with less than 100 ratings\n",
    "ratings_not100 = ratings[ratings['number_of_jokes_rated']<100]\n",
    "print(len(ratings_not100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly select an active user\n",
    "from random import sample \n",
    "\n",
    "user_ids = list(ratings_not100['user_id'])\n",
    "active_user = sample(user_ids,1)[0]\n",
    "active_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get active user's rating for each joke_id\n",
    "active_user_ratings = ratings_not100[ratings_not100['user_id']==active_user]\n",
    "active_user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_rating = pd.DataFrame()\n",
    "jokes_ids = list(range(1,101))\n",
    "user_rating = []\n",
    "\n",
    "for i in range(100):\n",
    "    user_rating.append(active_user_ratings.iloc[0,i])\n",
    "\n",
    "jokes_rating['joke_id']= pd.Series(jokes_ids)\n",
    "jokes_rating['rating'] = pd.Series(user_rating)\n",
    "\n",
    "#Print active user's rating for each joke\n",
    "jokes_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join jokes_rating and topics\n",
    "\n",
    "jokes = pd.read_csv(\"data/jokes_sorted_topic.csv\")\n",
    "jokes_topic = jokes[['joke_id','main_topic']]\n",
    "\n",
    "active_user_ratings = pd.merge(jokes_rating,jokes_topic,on='joke_id')\n",
    "\n",
    "#Sort user ratings in descending order\n",
    "active_user_ratings.sort_values(by=['rating'],ascending=False, inplace=True)\n",
    "\n",
    "#Print user's rating sorted in descending\n",
    "active_user_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend joke to user based on highly rated topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of active users ratings\n",
    "\n",
    "sns.distplot(active_user_ratings['rating'], kde = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting topics with ratings greater than 0.8\n",
    "\n",
    "interested_topics = active_user_ratings[active_user_ratings['rating']>0.8]\n",
    "interested_topics = set(interested_topics['main_topic'])\n",
    "interested_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly select 3 interested topics\n",
    "\n",
    "from random import sample \n",
    "\n",
    "random_interested_topics = sample(interested_topics,3)\n",
    "random_interested_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the jokes belonging to interested topic\n",
    "\n",
    "jokes2 = pd.read_csv(\"data/jokes_sorted_topic.csv\")\n",
    "\n",
    "selected_joke_ids = []\n",
    "\n",
    "for i in range(len(jokes2)):\n",
    "    if jokes2.iloc[i]['main_topic'] in random_interested_topics:\n",
    "        selected_joke_ids.append(jokes2.iloc[i]['joke_id'])\n",
    "\n",
    "#Number of jokes belonging to interested topic\n",
    "print(len(selected_joke_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select not rated jokes from interested topics\n",
    "jokes_unrated = active_user_ratings[active_user_ratings['rating'].isnull()]\n",
    "unrated_and_interested = jokes_unrated[jokes_unrated['main_topic'].isin(random_interested_topics)]\n",
    "unrated_and_interested.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly select a joke to recommend\n",
    "unrated_and_interested.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommend a joke only from the rated jokes for evalaluation only\n",
    "jokes_rated = active_user_ratings[active_user_ratings['rating'].notnull()]\n",
    "rated_and_interested = jokes_rated[jokes_rated['main_topic'].isin(random_interested_topics)]\n",
    "rated_and_interested.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly select a joke to recommend\n",
    "recommeded_joke = rated_and_interested.sample()\n",
    "recommeded_joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select all jokes rated by the user for training data\n",
    "jokes_filtered = pd.read_csv(\"data/jokes_postags_filtered.csv\")\n",
    "jokes_data = pd.merge(jokes_rated,jokes_filtered,on='joke_id')\n",
    "jokes_data = jokes_data[['joke_id','rating','cleanedText4']]\n",
    "jokes_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model to predict the ratings for the active user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model to predict rating from tf-idf\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('Tf-Idf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('classifier', RandomForestRegressor(max_depth=10))\n",
    "])\n",
    "\n",
    "X = jokes_data['cleanedText4']\n",
    "Y = jokes_data['rating']\n",
    "\n",
    "review_train, review_test, label_train, label_test = train_test_split(X, Y, test_size=0.2)\n",
    "pipeline.fit(review_train, label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict rating of recommended joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jid = recommeded_joke['joke_id'].iloc[0]\n",
    "text_data = jokes_data[jokes_data['joke_id']==jid]\n",
    "pip_pred = pipeline.predict(text_data['cleanedText4'])\n",
    "pip_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(text_data['rating'], pip_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------\n",
    "                                    END\n",
    "\n",
    "-----------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
